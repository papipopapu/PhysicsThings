{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b4016cb4",
      "metadata": {
        "id": "b4016cb4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import typing as tp\n",
        "import math\n",
        "import inspect\n",
        "def check(bruh):\n",
        "    print(\"Is this a class name?... \"+str(inspect.isclass(bruh)))\n",
        "class NeuralNetwork:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "id": "a44ea72e",
      "metadata": {
        "id": "a44ea72e"
      },
      "outputs": [],
      "source": [
        "class Layer:\n",
        "  def __init__(self, OutputSize: int, Depth: int, ActivationFunction):\n",
        "    self._WEIGHTS = np.zeros((OutputSize, Depth)) # Make zeros later, when we have initialization functionality\n",
        "    self._BIASES = np.zeros(OutputSize) # biases to zero by defect\n",
        "    self._ACTIVATION = ActivationFunction\n",
        "\n",
        "\n",
        "\n",
        "class Initializer:\n",
        "  pass\n",
        "class HeWeight(Initializer):\n",
        "  def Initialize(LayerList: tp.List[Layer]) -> tp.List[Layer]:                                                     \n",
        "    for L in LayerList:\n",
        "      L._WEIGHTS = np.random.normal(0, math.sqrt(2/L._WEIGHTS.shape[1]), size = L._WEIGHTS.shape)\n",
        "    return LayerList\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class LossFunction: \n",
        "    pass \n",
        "class MSE(LossFunction): # Includes Regularization, Mean Squared Error\n",
        "    def __init__(self, Lambda):\n",
        "        self._Lambda = Lambda # Lambda for L2 regularization\n",
        "        self.__LastOutput = np.zeros((1,1))\n",
        "        \n",
        "    def f(self, NNET: NeuralNetwork, Output: np.array, Truth: np.array):\n",
        "        L2 = 0\n",
        "        for L in NNET._LAYERS:\n",
        "            L2 += np.sum(L._WEIGHTS ** 2)            \n",
        "        return 0.5/Output.size * (np.sum((Output - Truth) ** 2) + self._Lambda * L2) # Watch out for Backprop and all that for L2\n",
        "    \n",
        "    def df(self, NNET: NeuralNetwork, Output: np.array, Truth: np.array) -> np.array:\n",
        "        return 1/Output.size * ((Output - Truth))\n",
        "    \n",
        "\n",
        "\n",
        "class ActivationFunction:\n",
        "    pass\n",
        "class RELU(ActivationFunction): # RELU activation, for other activations last output will be saved for faster derivative\n",
        "    def __init__(self):\n",
        "        self.f = np.vectorize(self.__f)\n",
        "        self.df = np.vectorize(self.__df)\n",
        "        \n",
        "    def __f(self, Input):\n",
        "        if Input > 0:\n",
        "            return Input\n",
        "        else:\n",
        "            return 0\n",
        "        \n",
        "    def __df(self, Input): \n",
        "        if Input > 0: \n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "        pass\n",
        "\n",
        "\n",
        "\n",
        "class Sigmoid(ActivationFunction):\n",
        "  def __init__(self):\n",
        "        self.__LastOutput = np.zeros((1,1))\n",
        "\n",
        "\n",
        "  def f(self, Input):\n",
        "        self.__LastOutput = 1/(1 + np.exp(-Input))\n",
        "        return self.__LastOutput\n",
        "\n",
        "        \n",
        "  def df(self, Input): \n",
        "        return np.multiply(self.__LastOutput, (1 - self.__LastOutput))\n",
        "  \n",
        "    \n",
        "    \n",
        "    \n",
        "class Optimizer:\n",
        "    pass\n",
        "class OptimizerExample(Optimizer):\n",
        "    def __init__(self, Alpha, Beta): \n",
        "        self.__Time = 0 # For decays and that, incremented each epoch maybe\n",
        "        self.__Alpha = Alpha # For momentum\n",
        "        self.__Beta = Beta # For momentum\n",
        "        self.__Vw = [] # Update gradient for weights for nesterov Momentum\n",
        "        self.__Vb = [] # Update gradient for biases\n",
        "        self.__LastOutput = [] # Last output of each layer\n",
        "\n",
        "        self.__VPass = []\n",
        "        self.__VTemp = []\n",
        "        # ... Missing some other varibles for backpropagation\n",
        "        \n",
        "    def Optimize(self, NNET: NeuralNetwork, Input: np.array, Truth: np.array ) -> tp.Tuple[tp.List[np.array], tp.List[np.array]]:    \n",
        "        N = len(NNET._LAYERS)\n",
        "        InvOutputSize = 1/Truth[0].size\n",
        "        Loss = 0\n",
        "       \n",
        "\n",
        "        self.__Vw = [None] * N # Initialize variables to mantain consistance across epochs\n",
        "        self.__Vb = [None] * N\n",
        "        self.__LastOutput = [None] * N\n",
        "\n",
        "        self.__VPass = [None] * N\n",
        "        self.__VTemp = [None] * N\n",
        "\n",
        "    \n",
        "        for Temp in range(0, N):\n",
        "            self.__Vw[Temp] = np.zeros(NNET._LAYERS[Temp]._WEIGHTS.shape)  # Initialize prev Vw to 0's\n",
        "        \n",
        "        for Elem in range(0, Input.shape[0]): # For every element in training input batch\n",
        "            # Forward Propagation\n",
        "            self.__LastOutput[0] = NNET._LAYERS[0]._ACTIVATION.f(np.matmul(NNET._LAYERS[0]._WEIGHTS, Input[Elem]) + NNET._LAYERS[0]._BIASES) # First we need the input to propagate\n",
        "            for i in range(1, N):\n",
        "                self.__LastOutput[i] = NNET._LAYERS[i]._ACTIVATION.f(np.matmul(NNET._LAYERS[i]._WEIGHTS, self.__LastOutput[i-1]) + NNET._LAYERS[i]._BIASES) # Propagate forward and save outputs\n",
        "            # We get the error outside loop\n",
        "            Loss += NNET._LOSS.f(NNET, self.__LastOutput[N-1], Truth[Elem])\n",
        "\n",
        "\n",
        "           # print(NNET._WEIGHTS[N-1])\n",
        "            \n",
        "\n",
        "\n",
        "            # Backpropagation\n",
        "            self.__VPass[N-1] = NNET._LOSS.df(NNET, self.__LastOutput[N-1], Truth[Elem]) # First propagation passed back is the derivative of the error (with respect to the output)\n",
        "            for i in range(N-1, 0, -1):\n",
        "                self.__VTemp[i] = np.multiply(self.__VPass[i], NNET._LAYERS[i]._ACTIVATION.df(self.__LastOutput[i])) # Useful Temp array (which is in reality dE/db, maybe later will be deprecated to optimize)\n",
        "               \n",
        "                self.__Vw[i] = self.__Alpha * np.outer(self.__VTemp[i], self.__LastOutput[i-1]) + self.__Beta * self.__Vw[i] +  NNET._LOSS._Lambda * InvOutputSize * NNET._LAYERS[i]._WEIGHTS # Weights gradient, includes L2 propagated. This will not be possible for firs layer, so we need outside loop function (we could include the input into the output list, but idk)\n",
        "                \n",
        "                self.__Vb[i] = self.__Alpha * self.__VTemp[i] # Biases gradient\n",
        "               \n",
        "                self.__VPass[i-1] = self.__VTemp[i].dot(NNET._LAYERS[i]._WEIGHTS) # Propagated error\n",
        "\n",
        "               # print(\"This should be (\"+str(self.__VTemp[i].size)+\", \"+str(self.__LastOutput[i-1].size)+\"): \" + str(self.__Vw[i].shape))\n",
        "               \n",
        "                NNET._LAYERS[i]._WEIGHTS -= self.__Vw[i] # Update parameters\n",
        "                NNET._LAYERS[i]._BIASES -= self.__Vb[i]\n",
        "\n",
        "            # First layer we do outside loop\n",
        "            self.__VTemp[0] = np.multiply(self.__VPass[0], NNET._LAYERS[0]._ACTIVATION.df(self.__LastOutput[0])) \n",
        "            self.__Vw[0] = self.__Alpha * np.outer(self.__VTemp[0], Input[Elem]) + self.__Beta * self.__Vw[0] +  NNET._LOSS._Lambda * InvOutputSize * NNET._LAYERS[0]._WEIGHTS\n",
        "            self.__Vb[0] = self.__Alpha * self.__VTemp[0] # Biases gradient \n",
        "            NNET._LAYERS[0]._WEIGHTS -= self.__Vw[0] # Update parameters\n",
        "            NNET._LAYERS[0]._BIASES -= self.__Vb[0]\n",
        "\n",
        "        if (self.__Time % 10 == 0):\n",
        "           print(\"Loss: \"+ str(Loss / Input.shape[0]))\n",
        "\n",
        "        #print(NNET._LAYERS[0]._WEIGHTS)\n",
        "\n",
        "  \n",
        "        self.__Time += 1\n",
        "        return NNET._LAYERS\n",
        "\n",
        "    \n",
        "class NeuralNetwork:\n",
        "    def __init__(self, ActivationFunctions: tp.List[ActivationFunction], Nodes: tp.List[int]):   \n",
        "        self._LAYERS = []     \n",
        "        self._LOSS = MSE(0) # Loss function, object\n",
        "\n",
        "        \n",
        "        # Add: \n",
        "        # Variable input and ouput sizes\n",
        "        # Different activation functions ~ start with ELU\n",
        "        # L1 regularization\n",
        "        # Nesterov SGD with momentum optimizer\n",
        "        # Initializer objects\n",
        "        # Dropout\n",
        "        \n",
        "        for i in range(1, len(Nodes)): # Initialize weights and biases sizes\n",
        "            self._LAYERS.append(Layer(Nodes[i], Nodes[i-1], ActivationFunctions[i-1]))\n",
        "\n",
        "    def InitializeParams(self, Initializer_: Initializer):\n",
        "      self._LAYERS = Initializer_.Initialize(self._LAYERS)\n",
        "\n",
        "\n",
        "    def Train(self, Input: np.array, Truth: np.array, Iterations: int, Optimizer_: Optimizer, LossFunction_: LossFunction = None ) -> None: # Truth.shape = (TrainingInstances, ElementsInEach), same for input     \n",
        " \n",
        "        if LossFunction_ is not None: # If other loss function is provided\n",
        "            self._LOSS = LossFunction_\n",
        "            \n",
        "        for Iter in np.arange(0, Iterations):\n",
        "                self._LAYERS = Optimizer_.Optimize(self, Input, Truth) # Optimizer updates biases and weights each epoch\n",
        "                \n",
        "    \n",
        "    def PredictOne(self, InputInstance: np.array) -> np.array:\n",
        "        Temp = 0\n",
        "        Temp = self._LAYERS[0]._ACTIVATION.f(np.matmul(self._LAYERS[0]._WEIGHTS, InputInstance) + self._LAYERS[0]._BIASES) # First we need the input to propagate\n",
        "        for i in range(1, len(self._LAYERS)):\n",
        "            Temp = self._LAYERS[i]._ACTIVATION.f(np.matmul(self._LAYERS[i]._WEIGHTS, Temp) + self._LAYERS[i]._BIASES) # Propagate forward and save outputs\n",
        "\n",
        "        return Temp\n",
        "    def Predict(self, Input: np.array) -> np.array:\n",
        "        Return = np.zeros((Input.shape[0], self._LAYERS[len(self._LAYERS)-1]._BIASES.size))\n",
        "        for k in range(0, Return.shape[0]):\n",
        "          Temp = self._LAYERS[0]._ACTIVATION.f(np.matmul(self._LAYERS[0]._WEIGHTS, Input[k]) + self._LAYERS[0]._BIASES) # First we need the input to propagate\n",
        "          for i in range(1, len(self._LAYERS)):\n",
        "              Temp = self._LAYERS[i]._ACTIVATION.f(np.matmul(self._LAYERS[i]._WEIGHTS, Temp) + self._LAYERS[i]._BIASES) # Propagate forward and save outputs\n",
        "          Return[k] = Temp\n",
        "\n",
        "        return Return\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "id": "d024a332",
      "metadata": {
        "id": "d024a332",
        "outputId": "24117525-b1e6-4958-d06c-8db2fe2df1ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.2050996659030044\n",
            "Loss: 0.20508275848792923\n",
            "Loss: 0.20508275848792923\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-200-407a3e1b4017>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptimizerExample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.003\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-182-352b781218b7>\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(self, Input, Truth, Iterations, Optimizer_, LossFunction_)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mIter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_LAYERS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptimizer_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTruth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Optimizer updates biases and weights each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-182-352b781218b7>\u001b[0m in \u001b[0;36mOptimize\u001b[0;34m(self, NNET, Input, Truth)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__VPass\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNNET\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_LOSS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNNET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__LastOutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTruth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mElem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# First propagation passed back is the derivative of the error (with respect to the output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__VTemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__VPass\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNNET\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_LAYERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ACTIVATION\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__LastOutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Useful Temp array (which is in reality dE/db, maybe later will be deprecated to optimize)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__Vw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__Alpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__VTemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__LastOutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__Beta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__Vw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0mNNET\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_LOSS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Lambda\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mInvOutputSize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mNNET\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_LAYERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_WEIGHTS\u001b[0m \u001b[0;31m# Weights gradient, includes L2 propagated. This will not be possible for firs layer, so we need outside loop function (we could include the input into the output list, but idk)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2078\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_and_out_core_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2080\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2081\u001b[0m         \"\"\"\n\u001b[1;32m   2082\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresults\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpyfunc\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mbroadcast\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvectorized\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "N = NeuralNetwork([RELU(), RELU(), RELU()], [1,100,100,1]) # Pass objects!!1\n",
        "N.InitializeParams(HeWeight)\n",
        "#print(N._LAYERS[0]._WEIGHTS)\n",
        "X = 2 * (np.random.rand(1000,1) - np.random.rand(1000,1) )\n",
        "Y = np.sin(X)\n",
        "N.Train(X, Y, 30, OptimizerExample(0.003, 0.0025), MSE(0))\n",
        "print(np.abs(Y-N.Predict(X)))\n",
        "print(Test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb6b8672",
      "metadata": {
        "id": "fb6b8672",
        "outputId": "59476fc2-4df3-4f5a-b633-3cfec18852db"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>.container { width:100% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "Ç  Çfrom IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "id": "b6d43bd3",
      "metadata": {
        "id": "b6d43bd3",
        "outputId": "5c5de598-441a-48a7-f0bb-322ba509189f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fce05866790>"
            ]
          },
          "metadata": {},
          "execution_count": 195
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.scatter(X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "id": "4005cf33",
      "metadata": {
        "id": "4005cf33"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "id": "0f17a648",
      "metadata": {
        "id": "0f17a648",
        "outputId": "dba51195-6e02-48be-e487-93c9491473e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fcdfd1a4610>"
            ]
          },
          "metadata": {},
          "execution_count": 198
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.scatter(X, N.Predict(X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75073cec",
      "metadata": {
        "id": "75073cec"
      },
      "outputs": [],
      "source": [
        "def testS(x):\n",
        "    print(np.matmul(np.ones((10,3)), x[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f30024d",
      "metadata": {
        "id": "8f30024d"
      },
      "outputs": [],
      "source": [
        "C = np.random.rand(6,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "916632be",
      "metadata": {
        "id": "916632be"
      },
      "outputs": [],
      "source": [
        "def temp(x):\n",
        "    print(x.size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8daeef4e",
      "metadata": {
        "id": "8daeef4e",
        "outputId": "daad1c8f-8233-4576-98c3-40d7ff652658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-d89f34e06de7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'numpy.random' has no attribute 'randrange'"
          ]
        }
      ],
      "source": [
        "X = np.random.randrange((3,8))\n",
        "Y = np.asarray([2,3,4])\n",
        "\n",
        "Y.dot(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23a5b951",
      "metadata": {
        "id": "23a5b951"
      },
      "source": [
        "temp(C)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e0430d2",
      "metadata": {
        "id": "7e0430d2"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit ('venv3': venv)",
      "language": "python",
      "name": "python3810jvsc74a57bd00fb76f2204baa4b88bd62e02626b1d627a276ef1a4dad37920da9ee4940b830b"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "NeuralNetwork.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}