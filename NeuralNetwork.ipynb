{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b4016cb4",
      "metadata": {
        "id": "b4016cb4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import typing as tp\n",
        "import math\n",
        "import inspect\n",
        "def check(bruh):\n",
        "    print(\"Is this a class name?... \"+str(inspect.isclass(bruh)))\n",
        "class NeuralNetwork:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a44ea72e",
      "metadata": {
        "id": "a44ea72e"
      },
      "outputs": [],
      "source": [
        "class LossFunction: \n",
        "    pass \n",
        "class MSE: # Includes Regularization, Mean Squared Error\n",
        "    def __init__(self, Lambda):\n",
        "        self.__Lambda = Lambda # Lambda for L2 regularization\n",
        "        self.__LastOutput = np.zeros((1,1))\n",
        "        \n",
        "    def f(self, NNET: NeuralNetwork, Output: np.array, Truth: np.array):\n",
        "        L2 = 0\n",
        "        for W in NNET.WEIGHTS:\n",
        "            L2 += np.sum(W ** 2)            \n",
        "        return 0.5/Output.size * np.sum((Output - Truth) ** 2) + self.__Lambda * L2 # Watch out for Backprop and all that for L2\n",
        "    \n",
        "    def df(self, NNET: NeuralNetwork, Output: np.array, Truth: np.array):\n",
        "        return 1/Output.size * np.sum((Output - Truth))\n",
        "    \n",
        "class ActivationFunction:\n",
        "    pass\n",
        "class RELU(ActivationFunction): # RELU activation, for other activations last output will be saved for faster derivative\n",
        "    def __init__(self):\n",
        "        self.__LastOutput = np.zeros((1,1))\n",
        "        self.f = np.vectorize(self.__f)\n",
        "        self.df = np.vectorize(self.__df)\n",
        "        \n",
        "    def __f(self, Input):\n",
        "        if Input > 0:\n",
        "            return Input\n",
        "        else:\n",
        "            return 0\n",
        "        \n",
        "    def __df(self, Input): \n",
        "        if Input > 0: \n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "        pass\n",
        "    \n",
        "    \n",
        "class Optimizer:\n",
        "    pass\n",
        "class OptimizerExample(Optimizer):\n",
        "    def __init__(self): \n",
        "        self.__Time = 0 # For decays and that, incremented each epoch maybe\n",
        "        self.__Vw = [] # Update gradient for weights\n",
        "        self.__VwPrev = [] # Previous update gradient, Nesterov momentum\n",
        "        self.__Vb = [] # Update gradient for biases\n",
        "        self.__LastOutput = [] # Last output of each layer\n",
        "        # ... Missing some other varibles for backpropagation\n",
        "        \n",
        "    def Optimize(self, NNET: NeuralNetwork, Input: np.array, Truth: np.array ) -> tp.Tuple[tp.List[np.array], tp.List[np.array]]:    \n",
        "        N = len(NNET._WEIGHTS)\n",
        "        \n",
        "        self.__Vw = [None] * N # Initialize variables to mantain consistance across epochs\n",
        "        self.__VwPrev = [None] * N\n",
        "        self.__Vb = [None] * N\n",
        "        self.__LastOutput = [None] * N\n",
        "    \n",
        "        for Temp in range(0, N):\n",
        "            self.__VwPrev[Temp] = np.zeros(NNET._WEIGHTS[Temp].shape)  # Initialize prev Vw to 0's\n",
        "        \n",
        "        for Elem in range(0, Input.shape[0]): # For every element in training input batch\n",
        "            # Forward Propagation\n",
        "            self.__LastOutput[0] = NNET._ACTIVATION[0].f(np.matmul(NNET._WEIGHTS[0], Input[Elem]) + NNET._BIASES[0]) # First we need the input to propagate\n",
        "            for i in range(1, N):\n",
        "                self.__LastOutput[i] = NNET._ACTIVATION[i].f(np.matmul(NNET._WEIGHTS[i], self.__LastOutput[i-1]) + NNET._BIASES[i]) # Propagate forward and save outputs\n",
        "                \n",
        "            print(self.__LastOutput[i])\n",
        "            \n",
        "        return NNET._WEIGHTS, NNET._BIASES\n",
        "\n",
        "    \n",
        "class NeuralNetwork:\n",
        "    def __init__(self, ActivationFunctions: tp.List[ActivationFunction], Nodes: tp.List[int]):        \n",
        "        self._ACTIVATION = ActivationFunctions # List with activation function, objects\n",
        "        self._LOSS = MSE(0) # Loss function, object\n",
        "        self._WEIGHTS = [] # Weight list \n",
        "        self._BIASES = [] # Biases list \n",
        "        \n",
        "        # Add: \n",
        "        # Variable input and ouput sizes\n",
        "        # Different activation functions ~ start with ELU\n",
        "        # L1 regularization\n",
        "        # Nesterov SGD with momentum optimizer\n",
        "        # Initializer objects\n",
        "        # Dropout\n",
        "        \n",
        "        for i in range(1, len(Nodes)-1): # Initialize weights and biases sizes\n",
        "            self._WEIGHTS.append(np.ones((Nodes[i], Nodes[i-1])))\n",
        "            self._BIASES.append(np.ones(Nodes[i]))\n",
        "            \n",
        "    def Train(self, Input: np.array, Truth: np.array, Iterations: int, Optimizer_: Optimizer, LossFunction_: LossFunction = None ) -> None: # Truth (TrainingInstances, ElementsInEach)        \n",
        " \n",
        "        if LossFunction_ is not None: # If other loss function is provided\n",
        "            self._LOSS = LossFunction_\n",
        "            \n",
        "        for Iter in np.arange(0, Iterations):\n",
        "                self._WEIGHTS, self._BIASES = Optimizer_.Optimize(self, Input, Truth) # Optimizer updates biases and weights each epoch\n",
        "                \n",
        "    \n",
        "            \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d024a332",
      "metadata": {
        "id": "d024a332",
        "outputId": "126434d9-3b61-4327-e074-0991d18aca63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is this a class name?... False\n",
            "[31.96644053 31.96644053 31.96644053 31.96644053 31.96644053 31.96644053\n",
            " 31.96644053 31.96644053]\n",
            "[31.96644053 31.96644053 31.96644053 31.96644053 31.96644053 31.96644053\n",
            " 31.96644053 31.96644053]\n",
            "[31.96644053 31.96644053 31.96644053 31.96644053 31.96644053 31.96644053\n",
            " 31.96644053 31.96644053]\n",
            "[31.96644053 31.96644053 31.96644053 31.96644053 31.96644053 31.96644053\n",
            " 31.96644053 31.96644053]\n",
            "[31.96644053 31.96644053 31.96644053 31.96644053 31.96644053 31.96644053\n",
            " 31.96644053 31.96644053]\n",
            "[31.96644053 31.96644053 31.96644053 31.96644053 31.96644053 31.96644053\n",
            " 31.96644053 31.96644053]\n",
            "[31.96644053 31.96644053 31.96644053 31.96644053 31.96644053 31.96644053\n",
            " 31.96644053 31.96644053]\n",
            "[31.96644053 31.96644053 31.96644053 31.96644053 31.96644053 31.96644053\n",
            " 31.96644053 31.96644053]\n",
            "[31.96644053 31.96644053 31.96644053 31.96644053 31.96644053 31.96644053\n",
            " 31.96644053 31.96644053]\n",
            "[31.96644053 31.96644053 31.96644053 31.96644053 31.96644053 31.96644053\n",
            " 31.96644053 31.96644053]\n"
          ]
        }
      ],
      "source": [
        "N = NeuralNetwork([RELU(), RELU()], [5,8,8,2]) # Pass objects!!1\n",
        "N.Train(np.random.rand(1,5), np.random.rand(10,2), 10, OptimizerExample())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb6b8672",
      "metadata": {
        "id": "fb6b8672",
        "outputId": "59476fc2-4df3-4f5a-b633-3cfec18852db"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>.container { width:100% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6d43bd3",
      "metadata": {
        "id": "b6d43bd3"
      },
      "outputs": [],
      "source": [
        "def notV(x):\n",
        "    if x<0:\n",
        "        return x\n",
        "    else:\n",
        "        return 1-math.exp(-x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4005cf33",
      "metadata": {
        "id": "4005cf33"
      },
      "outputs": [],
      "source": [
        "V = np.vectorize(notV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f17a648",
      "metadata": {
        "id": "0f17a648"
      },
      "outputs": [],
      "source": [
        "Y = np.random.rand(10,1)\n",
        "X = V(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75073cec",
      "metadata": {
        "id": "75073cec"
      },
      "outputs": [],
      "source": [
        "def testS(x):\n",
        "    print(np.matmul(np.ones((10,3)), x[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f30024d",
      "metadata": {
        "id": "8f30024d"
      },
      "outputs": [],
      "source": [
        "C = np.random.rand(6,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "916632be",
      "metadata": {
        "id": "916632be"
      },
      "outputs": [],
      "source": [
        "def temp(x):\n",
        "    print(x.size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8daeef4e",
      "metadata": {
        "id": "8daeef4e",
        "outputId": "116fd10d-8c62-4549-c640-514b9f45f226"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18\n"
          ]
        }
      ],
      "source": [
        "temp(C)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23a5b951",
      "metadata": {
        "id": "23a5b951"
      },
      "source": [
        "temp(C)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e0430d2",
      "metadata": {
        "id": "7e0430d2"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit ('venv3': venv)",
      "language": "python",
      "name": "python3810jvsc74a57bd00fb76f2204baa4b88bd62e02626b1d627a276ef1a4dad37920da9ee4940b830b"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "NeuralNetwork.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}